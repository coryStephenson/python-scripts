{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f39d9c17",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"JHU.png\" width=\"200\" alt=\"Johns Hopkins University logo\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b79c5",
   "metadata": {},
   "source": [
    "# Hands-on Lab: Generating Synthetic QR Codes with the Trained Generator\n",
    "\n",
    "Estimated time needed: **60** minutes\n",
    "\n",
    "### Overview:\n",
    "\n",
    "In this lab, we will develop a Generative Adversarial Network (GAN) to generate synthetic QR codes with embedded messages. We will start by creating a dataset of 100 QR codes, splitting it into training and validation sets. After preprocessing the images, we will build and train the GAN, consisting of a generator that produces QR codes and a discriminator that distinguishes between real and generated images. Over 5000 training epochs, we will optimize the GAN to create QR codes that are visually indistinguishable from the originals and contain the same messages when scanned. Finally, we will generate and save new QR codes to verify the performance of the generator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3688cc",
   "metadata": {},
   "source": [
    "### Learning Objectives:\n",
    "\n",
    "In this lab, we aim to achieve the following objectives:\n",
    "\n",
    "- Understand the principles of Generative Adversarial Networks (GANs).\n",
    "- Generate synthetic QR codes using a trained GAN model.\n",
    "- Build and optimize a generator and discriminator for the GAN.\n",
    "- Preprocess image data for effective training of the GAN.\n",
    "- Evaluate the performance of the GAN through generated outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee17bf1",
   "metadata": {},
   "source": [
    "### Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e286f4b7",
   "metadata": {},
   "source": [
    "#### Problem 1: Install Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142356f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.14.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (10.0.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
      "Collecting qrcode[pil]\n",
      "  Downloading qrcode-8.2-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.24.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.23.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (2.0.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.0)\n",
      "Downloading qrcode-8.2-py3-none-any.whl (45 kB)\n",
      "Installing collected packages: qrcode\n",
      "Successfully installed qrcode-8.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installing required libraries for generating QR codes and building the GAN\n",
    "!pip install qrcode[pil] tensorflow numpy pillow matplotlib\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import qrcode\n",
    "\n",
    "# TensorFlow and Keras imports\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Reshape, LeakyReLU, BatchNormalization, Conv2DTranspose\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Import necessary layers and optimizers\n",
    "# Write your code here \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc1e04c",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48da357",
   "metadata": {},
   "source": [
    "#### Problem 2: Create Directories for QR Code Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to store training QR codes\n",
    "os.makedirs('qr_codes/train', exist_ok=True)\n",
    "\n",
    "# Create directory to store validation QR codes\n",
    "# Write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e232df",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "os.makedirs('qr_codes/val', exist_ok=True)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e67dff",
   "metadata": {},
   "source": [
    "#### Problem 3: Generate QR Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ed8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate QR codes with embedded messages and save them as image files.\n",
    "def generate_qr_code(data, filename):\n",
    "    qr = qrcode.QRCode(version=1, box_size=10, border=5)\n",
    "    qr.add_data(data)\n",
    "    qr.make(fit=True)\n",
    "    img = qr.make_image(fill_color=\"black\", back_color=\"white\")\n",
    "    img.save(filename)\n",
    "\n",
    "# Generate a set of 80 training QR codes\n",
    "for i in range(80):\n",
    "    generate_qr_code(f\"Message {i}\", f\"qr_codes/train/qr_code_{i}.png\")\n",
    "\n",
    "# Generate a set of 20 validation QR codes\n",
    "# Write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78979219",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "for i in range(20):\n",
    "    generate_qr_code(f\"Message {i + 80}\", f\"qr_codes/val/qr_code_{i}.png\")\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bb8d66",
   "metadata": {},
   "source": [
    "#### Problem 4: Verify QR Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2f637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify if the QR code images have successfully generated\n",
    "# by counting the number of images in the training and validation directories.\n",
    "train_images = os.listdir('qr_codes/train')\n",
    "val_images = os.listdir('qr_codes/val')\n",
    "\n",
    "# Print the number of generated training and validation images\n",
    "# Write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93cc991",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "print(f\"Training images generated: {len(train_images)}\")\n",
    "print(f\"Validation images generated: {len(val_images)}\")\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287e754",
   "metadata": {},
   "source": [
    "#### Problem 5: Load and Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f54ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load images from a directory, resize them, and normalize pixel values for better GAN performance.\n",
    "def load_images(image_dir, target_size=(100, 100)):\n",
    "    images = []\n",
    "    filenames = os.listdir(image_dir)\n",
    "    for filename in filenames:\n",
    "        img = load_img(os.path.join(image_dir, filename), target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load the training and validation images\n",
    "train_images = load_images('qr_codes/train')\n",
    "val_images = load_images('qr_codes/val')\n",
    "\n",
    "# Normalize the images to the range [-1, 1]\n",
    "train_images = (train_images - 127.5) / 127.5\n",
    "val_images = (val_images - 127.5) / 127.5\n",
    "\n",
    "# Print the shape of the training and validation images\n",
    "# Write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b01381f",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "print(f\"Training images shape: {train_images.shape}\")\n",
    "print(f\"Validation images shape: {val_images.shape}\")\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7555e4ad",
   "metadata": {},
   "source": [
    "#### Problem 6:  Build the Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1162ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and construct the generator model for the GAN.\n",
    "# The model takes random noise as input and generates QR code images.\n",
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Initial dense layer to project the input noise into a higher-dimensional space\n",
    "    model.add(Dense(256 * 25 * 25, input_dim=100))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((25, 25, 256)))  # Reshape to a 3D tensor\n",
    "    \n",
    "    # First upsampling layer: Upsample to 50x50\n",
    "    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Second upsampling layer: Upsample to 100x100\n",
    "    model.add(Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Output layer: Generates a 100x100 image with 3 color channels\n",
    "    model.add(Conv2DTranspose(3, (4, 4), activation='tanh', padding='same'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the generator model and display the model's architecture\n",
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a68ed20",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "generator = build_generator()\n",
    "generator.summary()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ce93f",
   "metadata": {},
   "source": [
    "#### Problem 7: Build the Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c0482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and construct the discriminator model for the GAN.\n",
    "# The model classifies images as real or fake QR codes.\n",
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First convolutional layer: 64 filters, 3x3 kernel, same padding\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=(100, 100, 3)))\n",
    "    model.add(LeakyReLU(alpha=0.2))  # Leaky ReLU activation\n",
    "    model.add(Dropout(0.4))  # Dropout for regularization\n",
    "    \n",
    "    # Second convolutional layer: 128 filters, 3x3 kernel, downsampled by 2\n",
    "    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Third convolutional layer: 256 filters, 3x3 kernel, downsampled by 2\n",
    "    model.add(Conv2D(256, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Flatten the output for the final dense layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Output layer: Single neuron for binary classification with sigmoid activation\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build, compile the discriminator model with binary crossentropy loss and Adam optimizer, and display its architecture\n",
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306702d1",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "discriminator.summary()\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318d4c2",
   "metadata": {},
   "source": [
    "#### Problem 8: Build the Combined GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the generator and discriminator into a single model,\n",
    "# allowing the generator to be trained through the discriminator's feedback.\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False  # Freeze the discriminator during GAN training\n",
    "    \n",
    "    # Define the input and output for the GAN model\n",
    "    gan_input = generator.input\n",
    "    gan_output = discriminator(generator.output)\n",
    "    \n",
    "    # Create the GAN model\n",
    "    gan = Model(gan_input, gan_output)\n",
    "    \n",
    "    # Compile the GAN model with binary crossentropy loss and Adam optimizer\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "    \n",
    "    return gan\n",
    "\n",
    "# Build the GAN model and display its architecture\n",
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a786cee",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.summary()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6263eb77",
   "metadata": {},
   "source": [
    "#### Problem 9: Train the GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a99fb9",
   "metadata": {},
   "source": [
    "**You can experiment with different epoch values to find the optimal training duration. Be aware that running a large number of epochs may lead to kernel issues due to high resource usage.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff0947",
   "metadata": {},
   "source": [
    "> **Note**: Please be patient, as the execution may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395842fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for saving model checkpoints\n",
    "checkpoint_dir = 'gan_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Define a training function for the GAN, which alternates between\n",
    "# training the discriminator on real and fake images and training the generator.\n",
    "def train_gan(generator, discriminator, gan, epochs, batch_size, checkpoint_interval=100):\n",
    "    for epoch in range(epochs):\n",
    "        # Train the discriminator\n",
    "        idx = np.random.randint(0, train_images.shape[0], batch_size)  # Randomly select real images\n",
    "        real_images = train_images[idx]\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))  # Generate random noise\n",
    "        fake_images = generator.predict(noise)  # Generate fake images from noise\n",
    "\n",
    "        # Train the discriminator on real and fake images\n",
    "        d_loss_real = discriminator.train_on_batch(real_images, np.ones((batch_size, 1)))  # Real images labeled as 1\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_images, np.zeros((batch_size, 1)))  # Fake images labeled as 0\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)  # Average loss\n",
    "\n",
    "        # Train the generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))  # Generate new noise\n",
    "        g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))  # Label as 1 to fool the discriminator\n",
    "\n",
    "        # Print the progress every 100 epochs\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"{epoch} [D loss: {d_loss[0]} | D acc: {d_loss[1]}] [G loss: {g_loss}]\")\n",
    "        \n",
    "        # Save the model every checkpoint_interval epochs\n",
    "        if epoch % checkpoint_interval == 0:\n",
    "            generator.save(os.path.join(checkpoint_dir, f\"generator_epoch_{epoch}.h5\"))\n",
    "            discriminator.save(os.path.join(checkpoint_dir, f\"discriminator_epoch_{epoch}.h5\"))\n",
    "\n",
    "# Start training the GAN with 5000 epochs and a batch size of 32\n",
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa1996",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "train_gan(generator, discriminator, gan, epochs=5000, batch_size=32)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7fe0f0",
   "metadata": {},
   "source": [
    "#### Problem 10: Generate QR Codes from the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d6f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate and save QR codes from the trained generator\n",
    "def generate_and_save_qr_codes(generator, n_samples):\n",
    "    # Generate noise as input for the generator\n",
    "    noise = np.random.normal(0, 1, (n_samples, 100))\n",
    "    \n",
    "    # Use the generator to create fake images (QR codes)\n",
    "    generated_images = generator.predict(noise)\n",
    "    \n",
    "    # Rescale images from [-1, 1] to [0, 1] for proper display and saving\n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs('qr_codes/generated', exist_ok=True)\n",
    "    \n",
    "    # Save each generated QR code as an image\n",
    "    for i in range(n_samples):\n",
    "        plt.imshow(generated_images[i])\n",
    "        plt.axis('off')  # Turn off the axis for a cleaner look\n",
    "        plt.savefig(f\"qr_codes/generated/qr_code_{i}.png\")\n",
    "        plt.close()  # Close the figure to prevent memory overflow\n",
    "\n",
    "# Generate 10 QR codes using the trained generator\n",
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f69046c",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "generate_and_save_qr_codes(generator, 10)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a9192",
   "metadata": {},
   "source": [
    "> **Note**: The list of QR codes will be available in the internal environment. You can see the image below the path for the QR codes. Inside the 'qr_codes' folder, there are two additional folders: one for 'train' QR codes and another for 'generated' QR codes. The code above uses 'train' data to generate 10 QR codes, so you can use the code below to display both the trained and generated QR codes here.\n",
    "\n",
    "- Path for the Trained QR code: qr_codes/train/qr_code_1.png\n",
    "- Path for the Generated QR code: qr_codes/generated/qr_code_1.png\n",
    "\n",
    "You can change the last number from 1 to 9 in the path, such as **qr_codes/generated/qr_code_9.png**, to display the corresponding QR code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99f0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Load and display a real QR code from the training dataset\n",
    "def display_real_qr_code():\n",
    "    real_image_path = 'qr_codes/generated/qr_code_0.png'  # You can change the filename to display another QR code\n",
    "    real_image = load_img(real_image_path, target_size=(100, 100))\n",
    "    \n",
    "    # Convert the image to an array\n",
    "    real_image_array = img_to_array(real_image) / 255.0  # Normalize to [0, 1] for display\n",
    "    \n",
    "    # Display the real QR code\n",
    "    plt.imshow(real_image_array)\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.title('Real QR Code')\n",
    "    plt.show()\n",
    "\n",
    "display_real_qr_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9e8f69",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "GAN-generated images, such as QR codes, can sometimes appear noisy due to the inherent difficulty in balancing the training of the generator and discriminator. During early epochs, the generator may struggle to create realistic outputs, causing visual noise in the QR codes. This noise may also arise if the generator's learning process is unstable, or if the model fails to properly capture the features of the real QR codes.\n",
    "\n",
    "**Why Noise is Generated:**\n",
    "- **Insufficient Training:** If the GAN is not trained for enough epochs or is not optimized, the generator produces noisy or incomplete images.\n",
    "- **Imbalance Between Generator and Discriminator:** If the discriminator becomes too good too quickly, the generator fails to learn properly, leading to noise.\n",
    "- **Random Noise Input:** The generator uses random noise as input, and in earlier epochs, it struggles to convert this noise into meaningful features like clean QR codes.\n",
    "\n",
    "**How to Improve and Get Clear QR Codes:**\n",
    "1. **Increase Training Epochs:** Run the GAN for more epochs to allow the generator more time to learn the features of clean QR codes.\n",
    "2. **Adjust Batch Size:** Lowering the batch size can sometimes improve the quality of generated images, allowing the generator to update weights more frequently.\n",
    "3. **Use Smoothing Techniques:** Apply post-processing techniques like Gaussian filtering to smoothen the generated images.\n",
    "4. **Tune Model Hyperparameters:** Adjust learning rates, optimizer choices, or loss functions for better stability in GAN training.\n",
    "\n",
    "> By carefully tuning these parameters, you can generate clear, readable QR codes that effectively maintain the embedded message. We recommend that you try these experiments on a local machine, preferably one with high performance, as they may consume more memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4f0a22",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "In this lab, we successfully implemented a Generative Adversarial Network (GAN) to create synthetic QR codes. By generating a dataset of QR codes and training the GAN, we achieved a generator capable of producing QR codes that closely resemble real ones while retaining the embedded messages. Through hands-on experience with building and optimizing both the generator and discriminator, we deepened our understanding of GANs and their applications in synthetic data generation. The results demonstrate the potential of GANs in various fields, including data augmentation and creative applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
